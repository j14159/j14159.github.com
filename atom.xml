<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[NoisyCode]]></title>
  <link href="http://noisycode.com/atom.xml" rel="self"/>
  <link href="http://noisycode.com/"/>
  <updated>2016-05-27T19:43:29-07:00</updated>
  <id>http://noisycode.com/</id>
  <author>
    <name><![CDATA[Jeremy Pierre]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ADTs and Unification]]></title>
    <link href="http://noisycode.com/blog/2016/05/27/adts-and-unification/"/>
    <updated>2016-05-27T18:44:16-07:00</updated>
    <id>http://noisycode.com/blog/2016/05/27/adts-and-unification</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been tinkering with a statically-typed language for the Erlang VM for the
past few months, up until recently little more than an ML-shaped front for
Core Erlang with a type inferencer and incomplete support for basic Erlang
stuff.  Before fleshing out some of the required bits (like binaries), I&rsquo;m
working through implementing simple abstract data types.  I&rsquo;m aiming for
something roughly analogous to OCaml&rsquo;s variants or Haskell&rsquo;s GADTs.  Essentially
I want something like the following to work:</p>

<pre><code>type my_list 'x = Nil | Cons ('x, my_list 'x)
</code></pre>

<p>but also:</p>

<pre><code>type json_subset =  int
                  | string
                  | (string, json_subset)
                  | Array (list json_subset)
</code></pre>

<p>It&rsquo;s the latter that makes type unification a bit squirelly and this post is
mostly thinking through how I&rsquo;m going to attempt it at first.  It&rsquo;s entirely
possible I don&rsquo;t fully understand the problem I&rsquo;m trying to tackle yet but as
this entire project is an attempt to better understand type inference and
checking I&rsquo;m pretty OK with that.</p>

<p>For clarity, the unification function gets called currently in the following
situations:</p>

<ul>
<li>for items being cons&rsquo;d together into a list</li>
<li>across all pattern match clauses to type the match (all patterns must unify
with each other, all result types must unify as well)</li>
<li>inside each clause to ensure the types forced by guard functions match the
types in the result expression</li>
<li>inside each guard, sort of a special case of function application that I can
likely generalize better.</li>
<li>Erlang FFI returns.  These look like pattern matches but only the result
portion of each clause is checked.</li>
<li>function application.</li>
</ul>


<p>A cleaner example to describe the problem is based on the following types:</p>

<pre><code>type t = int | A int
type u = int | float
type v = int | float | (string, float)
</code></pre>

<p>Inferencing of basic matches already works, e.g.</p>

<pre><code>f x = match x with
    0 -&gt; :zero
  | 1 -&gt; :one
  | _ -&gt; :more_than_one
</code></pre>

<p>will type to <code>{t_arrow, [{t_int}], t_atom}</code> meaning &ldquo;a function from integers to
atoms&rdquo;.  What I&rsquo;d like is for</p>

<pre><code>f x = match x with
    i, is_integer i -&gt; :int
  | A _             -&gt; :got_an_A
</code></pre>

<p>to type to <code>{t_arrow, [{t_adt, "t"}], t_atom}</code> but this won&rsquo;t be too hard
either.</p>

<p>The following is a little more difficult:</p>

<pre><code>f x = match x with
    i, is_integer i                 -&gt; :int_but_could_be_one_of_three_types
  | f, is_float f                   -&gt; :could_be_u_or_v
  | (s, f), is_string s, is_float f -&gt; :definitely_v
</code></pre>

<p>The first two clauses (when unified) are shaped like a <code>u</code> while the third makes
it a <code>v</code>.  Unification works by trying to unify only two types at a time at
present so in a naive implementation the first and second clauses will unify to
<code>{t_arrow, [{t_adt, "u"}], t_atom}</code> and the third will cause a unification
failure because there is no type encapsulating <code>u</code> and <code>v</code>.  I think I&rsquo;ve got
two options, aside from saying &ldquo;reorder your clauses&rdquo;:</p>

<ol>
<li>Rework <code>unify</code> to take a list of expressions instead of two.</li>
<li>Require a union type covering <code>v</code> and <code>u</code> in order to type</li>
</ol>


<p>I think #1 is better (&ldquo;just works&rdquo;) but I think I&rsquo;m going to choose #2 as at
moment the list of problems to solve before opening up the source is a bit nasty,
including but not limited to:</p>

<ul>
<li>type errors are nothing more than <code>{error, {cannot_unify, Type1, Type2}}</code> and
don&rsquo;t even include a line number.  &ldquo;User-hostile&rdquo; is an understatement.</li>
<li>documentation and testing facilities are nonexistent.  I&rsquo;ve got some
particular directions I want to go with both (mostly selfish learning stuff)
before I take the lid off.</li>
<li>a truly scary number of dialyzer errors.  That my type-checking language
doesn&rsquo;t type-check is a source of mild amusement for me at the moment.</li>
<li>pretty much zero support for compiling anything but a list of files.</li>
<li>some trivial-to-implement stuff like sending and receiving messages.</li>
<li>haven&rsquo;t even begun to tackle strings-vs-lists, etc.</li>
</ul>


<p>I&rsquo;ll probably make the repository public once at least the first three items of the above
list are done as right now those are the bits I&rsquo;m most embarassed about.</p>

<p>Extra bits for the curious:</p>

<ul>
<li>implemented using <a href="http://erlang.org/doc/man/leex.html">leex</a> and
<a href="http://erlang.org/doc/man/yecc.html">yecc</a> with the <code>cerl</code> and <code>compile</code>
modules to create Core Erlang ASTs and generate <code>.beam</code> files respectively.</li>
<li>has a basic FFI to Erlang, I haven&rsquo;t yet tried calling dializer so it requires
a set of clauses to type the result.</li>
<li>type checker was based initially on
<a href="http://okmij.org/ftp/ML/generalization.html">How OCaml type checker works</a>.</li>
<li>not much of a design behind the language at the moment.  Bits of syntax come
from Haskell, OCaml, and Elm at the moment.  It&rsquo;s grown as I&rsquo;ve learned.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recent Influences]]></title>
    <link href="http://noisycode.com/blog/2015/03/12/recent-influences/"/>
    <updated>2015-03-12T15:47:37-07:00</updated>
    <id>http://noisycode.com/blog/2015/03/12/recent-influences</id>
    <content type="html"><![CDATA[<p>Over a lunch the other day with <a href="https://twitter.com/agonigberg">Arthur</a> I let fly a number of references that I&rsquo;m sure I&rsquo;ve mentioned to others as well, and thought I should collect a few of them in one place.  Some of these talks, posts, and books are more recent than others but collectively they are some of the bigger influences on my developing view of what constitutes &ldquo;professionalism&rdquo; and generally improving some different aspects my life.  I&rsquo;ve tried to give credit to the people from whom I saw them where I remember.</p>

<p>By no means is this a complete list, it&rsquo;s simply those pieces that immediately came to mind as being influential for me within the last couple of years.</p>

<h2>On Being A Senior Engineer</h2>

<p>If memory serves, I first saw <a href="http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/">John Allspaw&rsquo;s post</a> mentioned in a tweet from <a href="https://twitter.com/coda">Coda Hale</a>.  My first reading was the cause of some immediate and serious introspection as I compared how I acted when first holding this title against Allspaw&rsquo;s ideal and found myself wanting.  Much of what is in his post is the current foundation of what I would consider to be professionalism and definitely contributes to some aspirational goals.</p>

<h2>Death By 1000 Paper Cuts</h2>

<p>I don&rsquo;t recall where I first saw <a href="http://juliepagano.tumblr.com/post/46206589124/my-experiences-in-tech-death-by-1000-paper-cuts">Julie Pagano&rsquo;s post</a> but it&rsquo;s one that made me start watching how I interact with my different communities, work included.  This was an excellent prompt for me to start examining how my approach at any given point is harming or helping the people around me.  I still have a lot of room for improvement but this was a great beginning kick in the ass.</p>

<h2>Leaders Eat Last</h2>

<p><a href="https://www.youtube.com/watch?v=ReRcHdeUG9Y">Simon Sinek&rsquo;s talk</a> (he has a <a href="http://www.amazon.ca/Leaders-Eat-Last-Together-Others/dp/1591845327">book</a> by the same name that I&rsquo;ve not yet read) was recommended to me by <a href="https://twitter.com/tylerweir">Tyler</a>.  The way Sinek explains what <em>makes</em> a leader and connects that into how we form groups and work together most efficiently is what initially struck me.  Tying the workings of our our brain chemistry into our interactions also changed some of my thinking about how to better support and participate in the various communities I value.  I&rsquo;ve worked in the dysfunctional type of organization he describes and I want to work in and build the opposite.</p>

<h2>Aurelius&#8217; Meditations</h2>

<p>A fairly well known book that I&rsquo;ll likely be re-reading every year or two for the rest of my life.  The main impacts my first reading had were making me more aware of my frustrated reactions and even anger, helping me manage them and better understand what actually matters.  The results (aided by my <a href="http://noisycode.com/blog/2014/12/07/becoming-better/">notebook system</a> for reflection) have been less fundamentally irrelevant frustration and better focus.  A large part of what Aurelius seemed to be struggling with in my first reading was finding balance with all of the different people and pressures surrounding him.  The <a href="http://www.amazon.ca/exec/obidos/ASIN/0812968255/farst-20">translation I read</a> was introduced to me by the <a href="http://farnamstreetblog.com">Farnam Street blog</a> &ndash; that Amazon link is an affiliate one for the blog (thanks to <a href="https://twitter.com/tylerweir">Tyler</a> for introducing me to Farnam Street).</p>

<h2>Speaking While Female</h2>

<p><a href="http://www.nytimes.com/2015/01/11/opinion/sunday/speaking-while-female.html">This NYT piece</a> has made me much more cognizant of how much I interrupt people and I&rsquo;m trying to rein this in.  I&rsquo;m not actually <em>participating</em> in a community if all I do is broadcast my opinion and try to talk over people.</p>

<h2>Burnout and Ops</h2>

<p><a href="https://www.usenix.org/conference/lisa14/conference-program/presentation/lehtonen">This presentation</a> from <a href="https://twitter.com/alrs">Lars Lehtonen</a> probably deserves watching a few times.  This one is <em>fantastic</em> for getting some perspective on what&rsquo;s actually valuable.  I&rsquo;m not sure who exactly I saw reference this at first but it was definitely one of <a href="https://twitter.com/randomfrequency">Vince</a>, <a href="https://twitter.com/wrathofchris">Chris</a>, or <a href="https://twitter.com/ook">Michael</a>.</p>

<h2>Keeping Reasonable Hours</h2>

<p><a href="http://www.alternet.org/story/154518/why_we_have_to_go_back_to_a_40-hour_work_week_to_keep_our_sanity">This post</a> was a prompt to consider two things:  what is actually valuable to me, and how can I focus on being more efficient and effective?  Since restricting the volume of hours I spend <em>directly</em> on work and bursting only when necessary, my effectiveness definitely seems to have increased.  It leaves more time for my brain to recuperate, my relationships (which also provide a form of recovery), and for me to work on generally improving things related to my career (e.g. reading computer science papers) and personal life.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cluster Reading List]]></title>
    <link href="http://noisycode.com/blog/2015/02/28/cluster-reading-list/"/>
    <updated>2015-02-28T14:28:38-08:00</updated>
    <id>http://noisycode.com/blog/2015/02/28/cluster-reading-list</id>
    <content type="html"><![CDATA[<p>At <a href="http://askuity.com">work</a> we use <a href="http://mesos.apache.org/">Mesos</a> to manage a dynamic pool of resources for our <a href="http://spark.apache.org">Spark</a> jobs and while I&rsquo;ve also dabbled with <a href="http://hadoop.apache.org/">Hadoop</a> in the past, I&rsquo;ve found my understanding of the mechanics and initial design concerns of all of the above a bit lacking.  Rather than parrotting the standard marketing lines, I wanted to understand the fundamental reasons and motivation behind treating a pool of machines (virtual or otherwise) as an anonymized pile of aggregate CPUs and RAM for many different types of work.  A non-exhaustive list of things I want to understand are:</p>

<ul>
<li>How are larger jobs broken down and parallelized?</li>
<li>How are parts of jobs made to coexist in an environment of constantly changing demands?</li>
<li>How do we ensure full utilization of extant resources and do we <em>need</em> to in a cloud environment as opposed to  simply scaling the resources?</li>
<li>While I understand the basics of being concerned with &ldquo;data locality&rdquo; (get the computation as close as possible to the data), what are some practical ways to achieve this in a general way, applicable to many applications?</li>
</ul>


<p>In hopes of answering these (and other) questions, I started to compile this reading list of papers that seemed like they would help answer them.  An earlier form of this list was posted as a gist <a href="https://gist.github.com/j14159/19d100a556effacd1475">here</a>.</p>

<p>At present I have completed the Google File System, MapReduce, and Microsoft Dryad papers, all of which I have thoroughly enjoyed reading and they have already contributed to a better understanding of how I should be approaching Spark.</p>

<h1>The List</h1>

<p>This list was built primarily by crawling through the references sections of a few different papers.  Some of these have come by way of suggestions from <a href="https://twitter.com/omarkj">Omar</a> and <a href="https://twitter.com/ook">Michael</a> as noted below.  In pursuit of a reasonable reading and study plan for myself, I tried to lay the material out in something of a logical path from early successes to more recent ideas and implementations.</p>

<p>If you feel I&rsquo;ve left out anything particularly awesome or am incorrect in any assumptions/descriptions with respect to the later papers, I&rsquo;d love to hear about it and will update my list accordingly.</p>

<h2>Fundamentals</h2>

<p>A brief list of papers and ideas that I thought would give me something of a foundation in what the main problems, concerns, and early solutions were.</p>

<ol>
<li><a href="http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">Google File System</a> &ndash; most of the later material references this paper and it seems like this enabled a lot of other ideas later on.  The distribution of chunks of a file around a cluster enables a lot of interesting data locality stuff.</li>
<li><a href="http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf">Google MapReduce</a> &ndash; a pretty lucid and well thought out divide-and-conquer approach to parallelizing a huge job.  The functional programming part of me loved the LISP shout-out/inspiration.</li>
<li><a href="http://research.microsoft.com/en-us/projects/dryad/eurosys07.pdf">Dryad</a> for a more fine-grained/raw approach to programming against a cluster.</li>
<li><a href="http://www.sigops.org/sosp/sosp09/papers/isard-sosp09.pdf">Quincy</a> is, from what I understand so far, a more detailed look at an alternative scheduler for Dryad.</li>
<li><a href="http://people.csail.mit.edu/matei/papers/2010/eurosys_delay_scheduling.pdf">Delay Scheduling</a> for a detailed look at a different Hadoop scheduler.  Note the involvement of <a href="https://twitter.com/matei_zaharia">Matei Zaharia</a> who later worked on both the Mesos and Spark projects.</li>
</ol>


<h2>Cluster Schedulers</h2>

<p>Just the two big ones here, unfortunately there don&rsquo;t seem to be any papers out there on Google&rsquo;s Borg project.</p>

<ol>
<li><a href="http://people.csail.mit.edu/matei/papers/2011/nsdi_mesos.pdf">Mesos</a> as mentioned above is what I currently use to manage Spark resources.</li>
<li><a href="http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Schwarzkopf.pdf">Omega</a> is (was?) a project whose aim is/was to fix shortcomings in Google&rsquo;s existing cluster scheduling/management system (assuming Borg).</li>
</ol>


<h2>More Programming Models</h2>

<ol>
<li><a href="https://www.usenix.org/legacy/event/osdi08/tech/full_papers/yu_y/yu_y.pdf">DryadLINQ</a> is a higher-level programming model built on top of Dryad.  Composition FTW.</li>
<li><a href="http://kowshik.github.io/JPregel/pregel_paper.pdf">Pregel</a> a graph processing paper from Google.  References Dryad as well but I&rsquo;m not sure how close it is as I haven&rsquo;t read it yet and it seems to be less about dataflow.</li>
<li><a href="http://db.cs.berkeley.edu/papers/nsdi10-hop.pdf">MapReduce Online</a> for an iterative MapReduce.</li>
<li><a href="http://vldb.org/pvldb/vol5/p716_yuchenglow_vldb2012.pdf">Distributed GraphLab</a> sounds like another graph-like computation model but one that embraces asynchrony and parallelism a bit more.  Possibly belongs in the next category but I&rsquo;m not sure yet.</li>
</ol>


<h2>Data Flow</h2>

<ol>
<li><a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf">MillWheel</a> as recommended by <a href="https://twitter.com/omarkj">Omar</a> talks about stream processing but does appear to tackle the problem with a form of computation graph that looks like a dataflow approach.</li>
<li><a href="http://sigops.org/sosp/sosp13/papers/p439-murray.pdf">Naiad</a> is relatively recent from Microsoft Research (2013) and intriguingly mentions &ldquo;cyclic dataflow&rdquo; (also via <a href="https://twitter.com/omarkj">Omar</a>).</li>
<li><a href="https://www.info.ucl.ac.be/~pvr/erlang14cameraready.pdf">Derflow</a> is about &ldquo;deterministic dataflow&rdquo; with Erlang.  Sounds too good to pass up.</li>
</ol>


<h2>Big Ideas</h2>

<ol>
<li><a href="http://research.cs.wisc.edu/htcondor/doc/condor-practice.pdf">Condor</a> is referenced both by MapReduce and Dryad as an inspiration for cluster management approaches so I&rsquo;ve added it to get a bit more perspective at the end.</li>
<li><a href="http://www.morganclaypool.com/doi/pdf/10.2200/S00193ED1V01Y200905CAC006">The Datacenter as a Computer</a> (thanks to <a href="https://twitter.com/ook">Michael</a> for the reminder) is a bit over 100 pages but seems to cover a lot more of Google&rsquo;s general approach to clusters and more.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IX and the Throughput/latency Tradeoff]]></title>
    <link href="http://noisycode.com/blog/2015/01/14/ix-and-the-throughput-slash-latency-tradeoff/"/>
    <updated>2015-01-14T19:22:22-08:00</updated>
    <id>http://noisycode.com/blog/2015/01/14/ix-and-the-throughput-slash-latency-tradeoff</id>
    <content type="html"><![CDATA[<p>Since <a href="https://twitter.com/saemg">Saem</a> put me onto the Coursera <a href="https://class.coursera.org/learning-003">&ldquo;Learning How To Learn&rdquo;</a> course and <a href="https://twitter.com/tavisrudd">Tavis</a> (as well as <a href="https://twitter.com/tylerweir">Tyler</a> iirc) pointed me at <a href="http://www.scotthyoung.com/blog/">Scott Young</a>, I&rsquo;ve been trying to figure out how to better approach learning all of the material I try to throw at myself.</p>

<p>This coming Monday for the <a href="https://plus.google.com/u/0/communities/110886264051164890990">Polyglot reading group</a> we&rsquo;re covering the <a href="https://www.usenix.org/conference/osdi14/technical-sessions/presentation/belay">IX protected dataplane OS</a> <a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-belay.pdf">paper</a> which describes a set of tradeoffs that operating systems must make when deciding how to handle IO (network in this case).</p>

<p>While initially skimming the paper to try to figure out how I might chunk it to build a more cohesive understanding, I realized that I had an intuitive grip on the tradeoff between throughput and latency but I&rsquo;d never tried to properly define it for myself.  Being able to clearly define something I think is a mark of actual understanding and builds the ability to leverage it.  I figured this would be a good exercise in that spirit and both Dr Oakley and Scott Young seem to agree from what I&rsquo;ve seen so far.</p>

<h1>My Attempt</h1>

<p>Describe throughput, latency, and the tradeoff between them as generally as possible but with a view to how they pertain to the IX paper.</p>

<h2>Throughput</h2>

<p>Is a measure of how much <em>uninterrupted</em> work can be done.</p>

<h2>Latency</h2>

<p>Is a measure of how long it takes from submission of some work until its completion.</p>

<p>I think &ldquo;submission&rdquo; is likely interchangeable with any of the following if you prefer:</p>

<ul>
<li>definition</li>
<li>creation</li>
<li>identification</li>
</ul>


<h2>The Tradeoff</h2>

<p>In a system with limited capacity to do work, latency is proportional to the ability to interrupt existing work.  If interruption of current work is <em>not</em> permitted, meaning existing work proceeds with <em>no breaks</em>, the latency is equivalent to the time it takes to complete the pre-existing work because the system cannot do the new work until it finishes the <em>existing</em> work.  If interruptions <em>are</em> permitted without restriction, throughput is entirely bound by the frequency of interruptions.</p>

<p>In a system that preempts work, the balance is struck by limiting the frequency of interruptions.</p>

<p>In a cooperative system, the balance is struck by yielding control after an alotted amount of work is done (note that this depends on altruistic workers).</p>

<h1>Next</h1>

<p>I&rsquo;m going to try to apply this same sort of approach for simpler base concepts.  I think it&rsquo;s roughly in line with the <a href="http://www.scotthyoung.com/learnonsteroids/grab/TranscriptFeynman.pdf">Feynman technique</a> albeit simplified for the moment perhaps.</p>

<p>If you disagree with my definition with respect to the IX paper, I&rsquo;d love to hear about it.  As mentioned I&rsquo;ve only skimmed the paper so far and so it&rsquo;s entirely likely my definition and/or understanding will change a bit as I dig in deeper.</p>

<h1>Update</h1>

<p>Thanks to <a href="https://twitter.com">Saem</a> poking holes in the above definition, I&rsquo;ve started to refine it a bit.  The primary issue he turned up is that nowhere did I specify a cost for the interruptions required by latency and this further turned up an error in my definition of latency.  I&rsquo;ve adjusted the definition of latency and the tradeoff as follows:</p>

<h2>Latency</h2>

<p>Is a measure of the time from submission of work until some acknowledgement that the work is proceeding.  Servicing latency requires a non-zero amount of work because the expected minimum of the acknowledgement itself is work.</p>

<p>Note that this definition is primarily concerned with responsiveness rather than completeness of the submitted work and that latency consumes some measure of available throughput since it requires work.</p>

<h2>The Tradeoff</h2>

<p>A system with a limited capacity to do work, like a computer, is one with a bounded or static throughput.  In order for this system to provide the lowest possible latency, it must be able to interrupt existing work without restriction and consume throughput for <em>at least</em> acknowledgement of the receipt of new work.  On the other hand, to provide the highest possible throughput the system must prevent interruptions that also wish to consume its limited resource in favour of any existing work&rsquo;s use of it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Becoming Better]]></title>
    <link href="http://noisycode.com/blog/2014/12/07/becoming-better/"/>
    <updated>2014-12-07T15:11:05-08:00</updated>
    <id>http://noisycode.com/blog/2014/12/07/becoming-better</id>
    <content type="html"><![CDATA[<blockquote><p>What harms us is persisting in self-deceit and ignorance.</p>

<p><cite>Marcus Aurelius</cite></p></blockquote>

<p>This post is an attempt by me to describe a few techniques/practices I&rsquo;m trying to use in the pursuit of becoming better.  What I&rsquo;m trying to improve is my knowledge, its application, my general behaviour, and consistency in all of these things.</p>

<p>The root of this endeavour can probably be traced back to <a href="https://twitter.com/saemg">Saem</a> asking me which notebook system I use as we and a few other friends suffer from a minor notebook addiction (<a href="http://paper-ya.com/">Paper-ya</a> is dangerous).  At the time I had never heard of <a href="http://www.bulletjournal.com/">bullet journalling</a> nor any of the other systems and none especially met how I tended to approach note taking.  After more recently discussing the concept of the <a href="http://www.reddit.com/r/NonZeroDay/comments/1qbxvz/the_gospel_of_uryans01_helpful_advice_for_anyone">non-zero day</a> with <a href="https://twitter.com/tylerweir">Tyler</a>, he sent me a link to a modern copy of <a href="http://www.artofmanliness.com/2014/11/17/introducing-the-ben-franklins-virtues-daily-record-journal/">Benjamin Franklin&rsquo;s journal</a>.  Reading the <a href="http://farnamstreetblog.com">Farmam Street</a> post on <a href="http://www.farnamstreetblog.com/2014/07/networked-knowledge-and-combinatorial-creativity/">common place books</a> was the final missing piece for me.</p>

<p>I&rsquo;m roughly 3 weeks in to this new process and am finding it quite useful.  After ranting to several people about it, <a href="https://twitter.com/omarkj">Omar</a> suggested I document what I&rsquo;m doing and here we are.</p>

<h1>Better?</h1>

<p>To be more specific, I&rsquo;m defining a &ldquo;better me&rdquo; as one who:</p>

<ul>
<li>creates more things (efficiently, valuing completeness)</li>
<li>wants to hear opposing view points and ideas in order to find the truth faster</li>
<li>has more knowledge</li>
<li>has more patience</li>
<li>is basically kinder and more supportive.</li>
</ul>


<p>I think the last point is something many of us might define differently.  I do not at all think that kindness means blanket acceptance of everything somebody else desires and neverending sympathy but rather showing everyone common decency, basic respect, and an interest in understanding where another person is coming from (their experiences, goals, limits).</p>

<h1>The Books</h1>

<p>In this pursuit of a better me, I use three different notebooks.</p>

<h2>The Franklin Journal</h2>

<p>As the reproduction I mentioned above sold out quickly and I already have more notebooks than I know what to do with, I&rsquo;m using a small pocket notebook for this.  The format is essentially the same as Franklin&rsquo;s with some small modifications, one of which is that each week gets a page for &ldquo;lessons learned last week&rdquo;.  This is just a space for me to detail any large overarching themes or things I discovered.  The chart tracking my failures at the <a href="http://www.artofmanliness.com/2008/06/01/the-virtuous-life-wrap-up/">13 virtues</a> on a daily basis is the same as in the reproduction.</p>

<p>As in Franklin&rsquo;s original, each day gets two dedicated pages:</p>

<ol>
<li>The Plan, a list of non-work goals I have for the day.  This is another difference in that I don&rsquo;t use a set schedule as Franklin did.  Between the tools for my job and Google Calendar I have enough tools to track and schedule based on hours, etc.</li>
<li>A set of &ldquo;goodness&rdquo; goals for the day.</li>
</ol>


<h3>The Plan</h3>

<p>Everything in my daily plan is related directly to my own personal goals and improvement.  This can include everything from dedicating time to a project (this blog post has been in a couple of Plans) to exercise and basic housework that needs doing.  What occurs in <em>every</em> Plan is reading.</p>

<p>Each daily plan has a goal of at least 40 pages read from the book I&rsquo;m currently working on as well as at least one longer form blog post or paper.  This has been very helpful in keeping my pace up and <a href="http://twitter.com/reiver">Charles</a> recently told me he similarly blocks off reading time in his calendar.  For blog posts and papers in this context, I try to look for things outside my normal areas of experience, such as articles on <a href="https://modelviewculture.com">Model View Culture</a> or even completely different areas of study such as (today) <a href="http://tannerlectures.utah.edu/_documents/a-to-z/s/sen80.pdf">Equality of What</a>.  That last one is a bit longer and more difficult for me so I&rsquo;m dedicating a few days to completely digest it.</p>

<p>Each item I complete gets a check-mark and each item I fail to complete gets an X.</p>

<h3>Doing Good</h3>

<p>As in Franklin&rsquo;s journal, this page is always titled &ldquo;what good will I do today?&rdquo;.  I&rsquo;m treating it as an exercise in reflecting on how I can make a positive contribution to the communities I participate in.  Based on <a href="https://www.linkedin.com/today/post/article/20141124163631-24454816-two-minutes-to-make-you-happier-at-work-in-life-and-over-the-holidays">an article on gratitude</a> posted recently by <a href="https://twitter.com/geordie_h/status/537966528474664960">Geordie</a>, I&rsquo;ve lately been trying to integrate expressing gratitude to others as part of this.</p>

<p>At the end of the day I add &ldquo;what good did I do?&rdquo; to the middle of this page and list what actions I have taken to positively impact the communities and people around me.</p>

<h3>Failing</h3>

<p>All of the above likely sounds relatively strict.  An important part of this so far for me has been to set the bar a bit high and <em>forgive myself</em> for failing.  It&rsquo;s an ongoing process of learning about how I spend my time and what I prioritize.  The Franklin journal helps me <em>measure</em> my progress so that I can see when I&rsquo;m lapsing and when I&rsquo;m improving &ndash;  a continous self-intervention.  The great thing about the Plan is that even if I don&rsquo;t complete <em>everything</em>, it&rsquo;s an easy way to make sure I have a non-zero day (or non-one, non-two, etc).</p>

<p>While I try to start every day by setting a Plan and Goodness goals, I have failed to do this a couple of times as well.  When this occurs, I borrow <a href="https://twitter.com/omarkj">Omar</a>&rsquo;s practice of performing a personal retrospective at the end of the day.  As in the agile software development side of things, I simply describe a 2-3 things I thought went well and 2-3 things I know I could have done better.  The key for me has been to keep the aspects of reflection and measurement unbroken.</p>

<h2>My Common Place Book</h2>

<p>I originally came across mention of this in Farnam Street&rsquo;s post &ldquo;<a href="http://www.farnamstreetblog.com/2014/11/how-do-people-get-new-ideas/">How Do People Get New Ideas?</a>&rdquo; which linked to a post on <a href="http://www.farnamstreetblog.com/2014/07/networked-knowledge-and-combinatorial-creativity/">combinatorial creativity</a>.  Before I knew the term &ldquo;common place book&rdquo;, this notebook started as a place for me to make general observations and notes about the papers I read and rough outlines of ideas and presentations.</p>

<p>It still serves these purposes but has become more focused on the following as well:</p>

<ul>
<li>Specific ideas and quotes from texts.  The quote I opened this post with is an entry, along with a few thoughts about it and some of the surrounding text.</li>
<li>My thoughts on the portions of texts I extract or sections of things I&rsquo;ve read.  If I disagree with something I read in a blog post, I expand on it in this book and come back to link other supporting or dissenting ideas and opinions to it.</li>
<li>Trying to synthesize a larger understanding of these items I latch onto.  Reading <a href="http://www.amazon.ca/Meditations-New-Translation-Marcus-Aurelius/dp/0812968255/ref=sr_1_1?ie=UTF8&amp;qid=1417997261&amp;sr=8-1&amp;keywords=meditations+gregory+hays">Meditations</a> was where this practice started to really take shape for me but elements of it helped earlier this year when reading <a href="http://dspace.mit.edu/handle/1721.1/5794">AIM-349</a>.  I suspect this sort of thing is second nature for those with more of a background in serious study.</li>
</ul>


<h2>My Project Book</h2>

<p>This is a bit of a side channel for possible product ideas and specific projects I want to plan in a bit more depth, all software related at present.  Here I try to describe ideas for projects more fully, sometimes mocking/sketching out what aspects of them might look like.  These descriptions and sketches are a minor form of private feasibility study or even gut check and have led to me discarding some ideas before wasting too much time on them.  Because this book often distills thoughts and research items from my common place book, it tends to fill at a slower pace than the other two notebooks.</p>

<h1>Tools</h1>

<p>For those also suffering from notebook addictions, here&rsquo;s what I&rsquo;m actually using:</p>

<ul>
<li>My Franklin journal is a lined <a href="http://www.leuchtturm1917.com/en/content/pocket-notebook">Leuchtturm pocket notebook</a>.  The size is pretty much perfect for the amount I write.</li>
<li>My common place book is (embarassingly?) a swag notebook from <a href="https://f5.com/">F5</a> made by Journalbooks, I believe <a href="http://www.journalbooks.com/products/24-hour/24-hour-journals/bohemian">this is the model</a>.  As it&rsquo;s almost full now, I have a dotted <a href="http://www.leuchtturm1917.com/en/content/medium-notebook">Leuchtterm replacement</a> ready to go.</li>
<li>My project book is a grid <a href="http://www.works.co.kr/product/product_detail.html?pid=81&amp;cid=010103&amp;type=maxi&amp;page=">Works notebook</a>.  I like the rubberized cover but the Leuchtterm and Rhodia papers are nicer.</li>
</ul>


<p>If you care about pens, I&rsquo;m pretty simple.  I stick to the <a href="http://www.zebrapen.com/product/f-301-ball-point-retractable-2/">Zebra F-301</a> currently with 1.0mm refills.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Akka and JDBC to Services]]></title>
    <link href="http://noisycode.com/blog/2014/07/27/akka-and-jdbc-to-services/"/>
    <updated>2014-07-27T14:05:00-07:00</updated>
    <id>http://noisycode.com/blog/2014/07/27/akka-and-jdbc-to-services</id>
    <content type="html"><![CDATA[<p>I started mapping out this post over a month ago after I saw another question about how to handle blocking database calls on the Akka mailing list.  I&rsquo;ve been working towards most of what follows over the last year and after discussing the basics with a few others in the <a href="http://www.meetup.com/PolyglotVancouver/">Vancouver Polyglot</a> community with some additional prompting from <a href="https://twitter.com/saemg">Saem</a>, I finally put this together (<a href="https://github.com/j14159/akka-jdbc-post">project link</a> for the lazy).</p>

<p>This represents my current thinking (as of roughly July 2014) about a reasonable approach to the problems of state, blocking, and failure for data store interaction within the confines of Scala and Akka.  This post specifically focuses on JDBC connections but is roughly applicable to any system that provides a blocking API.  I define &ldquo;reasonable approach&rdquo; to be one that has significant enough upsides to combat its explicitly acknowledged weaknesses and negatives (I&rsquo;ll get to those towards the end).  The particular approach I&rsquo;m outlining here is a way to structure an application such that you have some reasonable flexibility later on and some clear benefits up front, yielding a future-viable design.</p>

<h1>Actors And Databases</h1>

<p>The initial question often seems to be &ldquo;how do I handle JDBC/blocking calls with Akka&rdquo;, the answer to
which almost always involves &ldquo;bulkheading&rdquo; which we&rsquo;ll get to a bit later in this post.  The issue I want to tackle first is one of state.</p>

<p>Database connections:</p>

<ul>
<li><em>Are</em> state</li>
<li>Have a lifecycle (connected, in-transaction, disconnected, etc)</li>
<li>Are prone to errors (timeouts, network partitions, etc)</li>
</ul>


<p>Database connection lifecycles should be tied directly to an actor&rsquo;s lifecycle with errors on the connection handled by supervision.  A 1:1 Connection:<a href="http://en.wikipedia.org/wiki/Data_access_object">DAO</a> actor is specifically what I am advocating.  I don&rsquo;t think the DAO approach suffers from lack of acceptance or understanding so I&rsquo;m not going to get into specifics about it here.  The basics around actor-connection coupling are as follows:</p>

<ul>
<li><p>Actors get a connection factory method with the most basic type being <code>() =&gt; java.sql.Connection</code>.</p>

<p>This method can be constructed elsewhere, closing over the necessary <em>immutable</em> state required to instantiate a connection, e.g. JDBC URL.</p></li>
<li><p>On any crash, the connection simply gets closed and the replacement actor instance will lazily recreate its required connection.  Supervision strategies and preRestart() behaviour can be easily tailored to not always kill the connection as this default behaviour is obviously not always desirable.  Tearing down the connection and starting a new actor instance on a column index error is clearly extreme.</p></li>
</ul>


<div><script src='https://gist.github.com/00b097487976b6486513.js'></script>
<noscript><pre><code>  val databaseUrl = &quot;postgresql://some-hostname:5432/db-name&quot;

  Class.forName(&quot;my.sql.database.driver.classname&quot;)

  class BasicJdbcActor(connFac: () =&gt; Connection) extends Actor {
    lazy val conn = connFac()

    override def preRestart(why: Throwable, msg: Option[Any]): Unit = 
      try { conn.close() }
    
    def receive = {
      case anything =&gt; throw new Exception(&quot;Where's my implementation?&quot;)
    }
  }

  def connFac = () =&gt; DriverManager.getConnection(databaseUrl)

  def makeMeAnActor(sys: ActorSystem): ActorRef = 
    sys.actorOf(Props(new BasicJdbcActor(connFac)))
</code></pre></noscript></div>


<p>Anyone who has deployed Erlang/OTP or Akka applications into a production will have noticed the problem that I have just introduced:  Akka actors (like processes and gen_servers in Erlang) by default have an <strong>unbounded</strong> mailbox.  Since we&rsquo;re making blocking calls inside the database actor, when a burst of requests occurs they will all queue inside the actor&rsquo;s mailbox without any sort of back pressure.  Parallelism <em>partially</em> helps to solve this problem.</p>

<h2>Parallelism and Pooling</h2>

<p><a href="http://www.amazon.com/Release-It-Production-Ready-Pragmatic-Programmers/dp/0978739213">Release It!</a> advocates against writing one&rsquo;s own connection pool and in general I think Mr Nygard puts it fairly well:</p>

<blockquote><p>&hellip;I oppose anyone rolling their own connection pool class.  It is always more difficult than you
think to make a reliable, safe, high-performance connection pool.</p></blockquote>

<p>Having said that, I will now happily violate his basic rule as well as <a href="http://www.chrisstucchio.com/blog/2013/actors_vs_futures.html">Chris Stucchio&rsquo;s position</a> by saying the use of a <a href="http://doc.akka.io/docs/akka/2.3.4/scala/routing.html">router</a> and the previously mentioned supervision strategy applied to a pool of actors is reasonably sound, safer due to less sharing of mutable state (a traditional connection pool), and performant enough (with caveats to follow).</p>

<p><strong>UPDATE:</strong>  <a href="https://twitter.com/jroper">James Roper</a> was kind enough to correct some mistaken assumptions on part with respect to connection pooling below.  I&rsquo;ll be giving some thought over the next while as to a good way to leverage connection pooling within this approach.</p>

<p>Using supervision strategies to enable both configurable and <em>adaptable</em> responses to errors is better than an opaque connection pool.  Seth Falcon&rsquo;s <a href="https://github.com/seth/pooler">pooler</a> project (hat tip to <a href="https://twitter.com/jamesgolick">James</a> for suggesting it to me) is where I first started to understand how useful and fundamentally sane this approach can be.  While I think it is safe to assume that JVM connection pool implementations these days are fast enough and avoid things like <code>synchronized</code> and heavy locks, passing around a reference to such an object containing so much mutable state is at odds with much of what makes both Scala and Akka effective.</p>

<p>It is important to note that a realistic supervision strategy would not cause the actor in question to restart on every exception, discarding the existing connection and creating another.  If the connection itself has no problems, &ldquo;Resume&rdquo; is a perfectly legitimate response from the strategy in many cases.  Your strategy must be
tailored to your particular problem and requirements.</p>

<div><script src='https://gist.github.com/49606a5468c734fc6a28.js'></script>
<noscript><pre><code>// very naive, be more specific based on your problem:
val restartStrategy = OneForOneStrategy(
  maxNrOfRetries = 10, 
  withinTimeRange = 1 minute) {
  case _ =&gt; Restart
}

def newPool(sys: ActorSystem): ActorRef = {
  val props = Props(new BasicJdbcActor(connFac))
  val pool = RoundRobinPool(4, supervisorStrategy = restartStrategy)
  sys.actorOf(pool.props(props))
}
</code></pre></noscript></div>


<p>Those in the audience paying attention will note that even though we now have parallel handling of requests, we have still not solved the actual queue problem.  Two of the simplest solutions are:</p>

<ul>
<li>Limit the number of requests in flight with a different actor mailbox type:  <code>akka.dispatch.BoundedMailbox</code>.  The downside here is that message sends are now blocking which may add to throughput issues.</li>
<li>Use proper timeouts with the &ldquo;ask&rdquo; pattern and a <a href="http://doc.akka.io/docs/akka/2.3.4/common/circuitbreaker.html">circuit breaker</a> to fail faster and back off.  More on this approach later.</li>
</ul>


<h1>Bulkheading</h1>

<p>&ldquo;Bulkheading&rdquo; is a <a href="http://letitcrash.com/post/40755146949/tuning-dispatchers-in-akka-applications">pattern</a> used to protect one set of components from negative influence by one or more <em>different</em> sets of components in your system.  Here we&rsquo;re specifically concerned with preventing the set of actors making JDBC calls from using up all of the compute resources (threads) used for <em>other operations</em>, e.g. responding to web requests, recording metrics, reporting on JVM stats, etc.</p>

<p>As an example, let&rsquo;s suppose you have a simple application supporting a couple of basic GET requests:</p>

<ul>
<li><code>/user/:id</code> to get a specific user object from the database by ID</li>
<li><code>/ping</code> to check if the system is alive</li>
</ul>


<p>Further, let&rsquo;s assume you&rsquo;re using something like the Spray library and thus have actors servicing HTTP requests.  If your single Akka dispatcher has a maximum of N threads and you have M or more <em>parallel</em> user requests occurring at the same time, when M >= N any call to the <code>/ping</code> endpoint will block without a response until one or more of the user requests complete.  Lest you think that success or failure of these calls is guaranteed to be fast (or even to occur at all), I encourage you to read <a href="http://www.amazon.com/Release-It-Production-Ready-Pragmatic-Programmers/dp/0978739213">Release It!</a> at a minimum.</p>

<p>In order to <strong>bulkhead</strong> everything else from the JDBC actors, we create a different dispatcher for the database actors and spawn them only on this separate dispatcher.  Now the non-database components will not be affected when the database actors have blocked all of their threads.  Note that this is not a panacea &ndash; should all of the database actor threads be blocked, any component that relies on this pool of actors will be prevented from making progress until earlier calls complete.</p>

<p>Dispatcher configuration:</p>

<div><script src='https://gist.github.com/ab55d058c118f57075ae.js'></script>
<noscript><pre><code>my-dispatcher {
  type = Dispatcher
  executor = &quot;fork-join-executor&quot;
  fork-join-executor {
    parallelism-min = 2
 
   //2 threads per core
    parallelism-factor = 2.0

    // The max that the dispatcher will create:
    parallelism-max = 8
  }
}</code></pre></noscript></div>


<p>And a minor change to our pool with a router:</p>

<div><script src='https://gist.github.com/8219db85e98e2dc713d5.js'></script>
<noscript><pre><code>val props = Props(new BasicJdbcActor(connFac))
  .withDispatcher(&quot;my-dispatcher&quot;)
val pool = RoundRobinPool(4, supervisorStrategy = restartStrategy)
sys.actorOf(pool.props(props))</code></pre></noscript></div>


<p>This is just the beginning of isolating and protecting different pools of actors and tasks (e.g. futures).  While I don&rsquo;t want to get too deep into tuning dispatchers and prioritizing access for different components, you should be aware that there are a variety of ways to affect quality-of-service for clients of your actors.  Here are some of the simplest places to start:</p>

<ul>
<li>The number of threads per dispatcher (with high and low thresholds) can be adjusted as needed.  If you need more throughput, make more actors and give them correspondingly more threads.  Don&rsquo;t forget that running more connections has its own penalties and limitations.</li>
<li>A &ldquo;pinned&rdquo; dispatcher can be used wherein each actor gets its own thread all to itself.</li>
<li>For higher-priority clients, give them their own larger pool of actors on yet another dispatcher if necessary (almost last resort I think).</li>
</ul>


<h1>DAOs</h1>

<p>Those of you with some experience will note that I&rsquo;m actually conflating <a href="http://en.wikipedia.org/wiki/Data_access_object">DAO</a> and <a href="http://en.wikipedia.org/wiki/Domain-driven_design#Building_blocks_of_DDD">Aggregate Roots</a> for reasons that will become more clear shortly.</p>

<p>Each aggregate root gets an actor implementation that provides all of the necessary CRUD functionality or whatever subset is needed (a DAO with a message-passing interface).  In addition I favour creating unique case classes for each type of request that the DAO actor services rather than more ambiguous strings or tuples.  All interaction with the actor is performed via the <a href="http://doc.akka.io/docs/akka/2.3.4/scala/actors.html#Ask__Send-And-Receive-Future">ask pattern</a>.</p>

<p>Hiding CRUD mechanics is important because SQL or some DSL analogue appearing throughout your code and packages is a leak.  Data store details are details about serialization and with very few exceptions should <em>not</em> be leaking into your business logic.  &ldquo;Save this thing&rdquo;, &ldquo;find things that match these criteria&rdquo;, etc are not specific mechanics, they&rsquo;re closer to <em>goals</em> that need to be satisfied.  &ldquo;INSERT x INTO TABLE y&rdquo; are particulars that are not germane to your business logic.</p>

<div><script src='https://gist.github.com/6aee8831ffb10747f226.js'></script>
<noscript><pre><code>case class Person(name: String, email: String)
case class PersonById(id: Int)

class PersonDao(cf: () =&gt; Connection) extends Actor {
  lazy val conn = cf()

  override def preRestart(why: Throwable, msg: Option[Any]): Unit = 
    try { conn.close() }
  
  def receive = {
    case Person(n, e) =&gt;
      //call insert function with above connection
      sender ! 1 // mock person ID
    case PersonById(id) =&gt;
      //get person from connection above
      sender ! Person(&quot;name&quot;, &quot;email&quot;) // mock
  }
}
</code></pre></noscript></div>


<h1>Failure as a First Class Citizen</h1>

<p>Rather than the raw ask pattern, informed somewhat by common Erlang approaches to gen_server interfaces I always create a client trait  in front of the DAO actors returning <a href="http://www.scala-lang.org/api/2.10.3/?_ga=1.34556641.1524243934.1391722094#scala.concurrent.Future">Futures</a> that can easily be turned into a standalone class or object where necessary (e.g. testing).</p>

<div><script src='https://gist.github.com/ca191b61a73382316f9c.js'></script>
<noscript><pre><code>trait PersonClient {
  // supply a router with a pool of PersonDao:
  val personPool: ActorRef

  // how long should we wait for a response from PersonDao:
  val timeoutInMillis: Long

  implicit val timeout = Timeout(timeoutInMillis millis)

  def addPerson(p: Person): Future[Int] =
    (personPool ? p).mapTo[Int]

  def personById(id: Long): Future[Person] = 
    (personPool ? PersonById).mapTo[Person]
}
</code></pre></noscript></div>


<p>Why Futures?</p>

<ul>
<li>They keep failure handling front and centre via recover() and recoverWith() (I believe <a href="https://twitter.github.io/finagle/">Finagle</a> may be responsible for this).</li>
<li>Explicitly asynchronous.</li>
<li>Easy to combine and parallelize via map(), flatMap(), zip(), for-comprehensions, etc.</li>
</ul>


<p>The first point bears emphasis:  futures in Scala and Finagle expose failure and <em>doing something with that failure</em> as a primary concern.  For the simplified starting point described here, timeouts are the primary failure we&rsquo;re initially concerned with.  To that end, we can combine sensible timeouts with <a href="http://doc.akka.io/docs/akka/2.3.4/common/circuitbreaker.html">circuit breakers</a> to help solve the queue growth problem and keep our systems responsive.</p>

<p>On sensible timeout values, I will defer to <a href="http://queue.acm.org/detail.cfm?id=2187821">Pat Helland</a>:</p>

<blockquote><p>Some application developers may push for no timeout and argue it is OK to wait indefinitely. I typically propose they set the timeout to 30 years. That, in turn, generates a response that I need to be reasonable and not silly. Why is 30 years silly but infinity is reasonable? I have yet to see a messaging application that really wants to wait for an unbounded period of time&hellip;</p></blockquote>

<p>By embracing failures as legitimate responses, we can begin to build systems that degrade gracefully and continue to function in the face of most problems that occur (see most of what has been written by the Netflix team).  This point cannot be overstated:  when talking to a data store, you are explicitly making calls to an external and <em>very probably remote</em> system of some sort and thus failure <em>must</em> be accounted for and <em>must</em> be handled.</p>

<h1>Smells Like A Service</h1>

<p>When constructed with the above approach, an application has effectively been built as a set of internal services.  Since all of the clients talk to the internal services via a mechanism that expects failure and encourages its proper handling, you can simply swap out the implementation behind the scenes for remote services whenever such growth is necessary, e.g.</p>

<ul>
<li><a href="http://dispatch.databinder.net/Dispatch.html">Dispatch</a> HTTP calls already return futures.</li>
<li>Netty or Akka TCP clients writing to a <a href="http://www.scala-lang.org/api/2.10.3/?_ga=1.34556641.1524243934.1391722094#scala.concurrent.Promise">Promise</a>.</li>
<li>Actors talking to external services via RabbitMQ, 0MQ, etc (though not what I would <em>generally</em> recommend).</li>
</ul>


<p>It is far simpler to move functionality to an external application (separate service) in this manner than with a more traditional DAO or ORM approach.</p>

<h1>Explicit Negatives</h1>

<ul>
<li><p>Using the ask pattern means that responses from the actor are typed as <code>Any</code>, which effectively bypasses type checking.  One solution with its own issues is to send an already constructed promise with your message to the DAO actor using <code>tell</code>/<code>!</code>.  The DAO actor could then write a success or failure to this promise, yielding proper type safety but <strong>complicating</strong> timeouts.</p>

<p>If you rely entirely on the Akka circuit breaker implementation, the problem can be mostly solved.  Since the circuit breaker will return a failed future after a timeout you specify, you can send an already constructed Promise to the actor and give the circuit breaker the result of Promise.future.  Since the circuit breaker does not have access to the promise you constructed, you should have no problems with a race to write a result to it on low timeouts and/or slow actors (see the <a href="https://github.com/j14159/akka-jdbc-post">example project</a> for this method).</p></li>
<li><p>It should be fairly obvious that with complex problem domains and a lot of models the actor and thus connection count can get high.  When this occurs, you already have an interface that looks like a service and provides reasonable support for failure handling.  Move larger and/or high-traffic aggregate roots out of the application into actual separate services, swapping out the functionality behind the Future-based API without changing the interface.  The only difference to callers should be at most some different exception classes on failure and completion times.</p>

<p>While I think externalizing services like this is generally a great idea, exercise caution.  Move <a href="http://martinfowler.com/bliki/BoundedContext.html">bounded contexts</a> out first and don&rsquo;t forget that when you move to an external service, you add a set of latencies in serialization, deserialization, and additional network traffic.  Ensure that you both <em>measure</em> and account for this.</p></li>
<li>Connections are hidden so the functionality provided by your DAO actors must be complete (no arbitrary SQL).  You can get around this by building an actor that takes closures or something along those lines as transaction blocks.  See <a href="https://github.com/nkallen/querulous">Querolous</a> for this sort of idea but I think this is missing the point in the context of this particular discussion.</li>
<li>Transactions that span multiple aggregate roots are essentially impossible in any <em>traditional</em> sense (those that are handled entirely inside the database), as they also are in most honest distributed system designs.  People like <a href="http://www.ics.uci.edu/~cs223/papers/cidr07p15.pdf">Pat Helland</a> and <a href="http://www.bailis.org/">Peter Bailis</a> amongst many others are doing very interesting work in this area (apologies to the many deserving people I&rsquo;ve left out here, too many to name).</li>
<li>Timeouts are not guaranteed to trigger failure exactly when you want them to (it may take longer).</li>
<li>The router + actor approach introduces aspects of queue growth as described above so there is an obvious need for back pressure and capacity planning.  Circuit breakers help mitigate this but they&rsquo;re not a silver bullet.</li>
<li>Boilerplate.</li>
</ul>


<h1>The Immediate Benefits</h1>

<p>There are three particular benefits for any system, especially if done in the early stages of its life:</p>

<ul>
<li>APIs that are asynchronous, composable, and failure-centric.</li>
<li>Easily configurable parallelism and limits.</li>
<li>Comprehensible subcomponents (the most important benefit of service oriented architectures whether micro or otherwise).</li>
</ul>


<p>At present I think the above strengths combined with the relative ease of partitioning a system into other more granular services later on (not to mention CQRS and event sourcing) make this a reasonable approach to designing a system.  While I&rsquo;m not 100% happy with the boilerplate feeling I get at times, the concrete isolation of the models into their initially internal services has definitely helped me already to keep things clean and understandable.  Having said that, it is far from lost on me how much less code it takes to do the same thing in Erlang with the caveat that I have yet to see something comparable to futures in for-comprehensions there (please correct me if I&rsquo;m missing something like this!).  If you missed the two links above, my example project using the send-in-promises approach is <a href="https://github.com/j14159/akka-jdbc-post">available here</a>.</p>

<p>Thanks to <a href="https://twitter.com/saemg">Saem</a> and <a href="https://twitter.com/eddsteel">Ed</a> for proof reading and pointing out where more clarity was necessary.  Comments, criticism and general dicussion welcome in comments or on <a href="https://twitter.com/j14159">Twitter</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[eSpacewar Open Sourced]]></title>
    <link href="http://noisycode.com/blog/2013/03/09/espacewar-open-sourced/"/>
    <updated>2013-03-09T09:13:00-08:00</updated>
    <id>http://noisycode.com/blog/2013/03/09/espacewar-open-sourced</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/j14159/eSpacewar">GitHub link for the lazy</a></p>

<p><a href="http://esw.noisycode.com:8080/sw.html">Gameplay link for the lazy</a>, not guaranteed work <em>after</em> March 31, 2013</p>

<h2>What Is It?</h2>

<p>As <a href="http://noisycode.com/blog/2013/03/02/testing-erlang-spacewar/">mentioned previously</a>, I built an online multiplayer-only version of <a href="http://en.wikipedia.org/wiki/Spacewar!">Spacewar!</a> using <a href="http://erlang.org">Erlang</a> for all of the game logic and <a href="https://github.com/extend/cowboy">Cowboy</a> for websocket communication with clients.  The only client at present is a very simple HTML canvas one, <a href="https://github.com/j14159/eSpacewar/blob/master/priv/sw.html">here is a direct link</a>.</p>

<p><img src="http://static.ow.ly/photos/original/1E7sr.png"></p>

<h2>Why?</h2>

<h3>The Basics</h3>

<p>I wanted to validate a couple of choices for building simple things requiring:</p>

<ul>
<li>the communication of some universal state to clients on a rapid basis</li>
<li>changing that state based on input from a variety of clients</li>
</ul>


<p>Looks like a game, sounds like a game but applicable to a lot of other stuff.</p>

<h3>Learning Erlang</h3>

<p>Aside from my (so-far) abortive attempt to build a <a href="https://github.com/j14159/PawnShop">URL-shortener</a>, I haven&rsquo;t found an excuse to really dig into Erlang yet.  At the same time, I have been thinking for a while about the possibility of simple games via websockets.  The concurrency and responsiveness requirements for something like this make Erlang a natural choice.</p>

<h3>More With Websockets</h3>

<p>They&rsquo;re still sort of stuck in standards-hell and probably not as good as they could be but I wanted to try them out in more depth.  I didn&rsquo;t consider comet for this because the nature of Spacewar requires a lot of small, rapid updates and I <em>suspected</em> (but cannot yet confirm) that the repeated connection setup overhead <em>might</em> negatively impact this.</p>

<p><strong>In actual fact</strong>, my assumption/suspicion is extremely likely to be <strong>totally wrong</strong> for the scope of this project.  It probably only makes a difference at an extremely high rate of messages (eSpacewar does a minimum of 20/second to each client) which I&rsquo;m obviously not dealing with here.</p>

<h3>Derp Cloud Derp</h3>

<p>This one&rsquo;s easy.  I just wanted to see if a tiny EC2 node could actually handle it.  It mostly can but the t1.micro it&rsquo;s hosted on now tends to stutter occassionally.</p>

<h2>What I Liked</h2>

<h3>Erlang</h3>

<p>I could probably go on forever about this (but won&rsquo;t here).  A few specific points that I ended up really loving:</p>

<ul>
<li>Pattern matching permeates <em>everything</em> to the point that if/then/else just seems medieval.</li>
<li>So easy to avoid shared state.  You just don&rsquo;t have any option (slight lie, go with it) so it makes things easier to keep clean.</li>
<li>Clean, simple and minimal.  The core is so small and the emphasis on recursion so high that you&rsquo;re naturally pushed to composability (although you&rsquo;ll likely find gross contradictions in my code).</li>
</ul>


<p>I didn&rsquo;t actually make much use of supervision so can&rsquo;t comment on that yet (but love it in the Akka/Scala world).</p>

<h3>Turns Out People Like It</h3>

<p>Who knew?  Simple gameplay, easy to drop in and low requirements.  I&rsquo;ve seen some great 10 player moments of mayhem.  Would have liked to see more but I think it would make playing almost impossible due to the number of torpedoes flying around.</p>

<h2>What I Screwed Up</h2>

<p>This is a non-exhaustive list, see code and comments for more but these are the big things I <em>think</em> I could have done better.  Please feel free to hit me up with agreements/disagreements and suggestions on <a href="http://twitter.com/j14159">Twitter</a> or in the comments.</p>

<h3>Unit Tests</h3>

<p>There aren&rsquo;t any.  I pretty much just slammed through this project to get things working and learn what I could.</p>

<h3>Collision Detection</h3>

<p>Collision detection occurs <em>after</em> an entity (torpedo, player) has been moved and is based on points in space.  This means that if players and/or torpedoes are moving quickly, they can appear to pass through each other.  This could be solved by using line segments to see if paths cross.</p>

<p>A further issue is that the server side has no concept of the ship&rsquo;s shape.  It considers a ship to be a point with a certain bounding area and only registers a collision if two entities overlap.</p>

<h3>handle_info</h3>

<p>My gen_server and gen_fsm implementations (see <a href="https://github.com/j14159/eSpacewar/blob/master/src/space.erl">space.erl</a> and <a href="https://github.com/j14159/eSpacewar/blob/master/src/player.erl">player.erl</a> respectively for examples) could possibly be simplified a bit by using handle_info over handle_cast or specific states in some cases.  More importantly, this may have made the move from basic processes to gen_server and gen_fsm a little easier.</p>

<p>I would most definitely welcome opinions for and/or against the above, I clearly still have a lot to learn.</p>

<h3>Records</h3>

<p>I ended up not using records (just haven&rsquo;t looked closely at them yet) and used tuples everywhere.  I suspect I may have been able to simplify some state by using these but am unsure of how this would impact some of my pattern matching use.  I&rsquo;m aware they&rsquo;re an extension of tuples but don&rsquo;t know if this enforces a certain structure.  An area for futher exploration.</p>

<h3>Client</h3>

<p>I&rsquo;m clearly not an experienced JavaScript developer and need improvement (the playing space size is hard-coded, bad).  One of the areas I <em>wanted</em> to get into but didn&rsquo;t is WebGL but I&rsquo;ll leave that for later.</p>

<h2>Conclusions</h2>

<p>I put this into a repo at a fairly early state so you will be able to dig back and see the progression (it was much uglier before).</p>

<p>As a result of this project, I&rsquo;m confident enough with Erlang (and Cowboy) to start applying it to some more advanced/involved things so I&rsquo;m going to push on with some new projects.  I&rsquo;ll undoubtably be posting progress on those at some time soon.</p>

<p>The problems above, unfortunately, likely won&rsquo;t get fixed.  I&rsquo;ve essentially learned what I set out to and eSpacewar has served well for that process.  Feel free to fork/host/modify, I&rsquo;d appreciate a link to this blog if you decide to host it (or some derivative) somewhere else.</p>

<p>Comments/criticism most welcome on <a href="http://twitter.com/j14159">Twitter</a> and in the comments below.  I&rsquo;ll consider pull requests on GitHub but don&rsquo;t really want to mess with this too much further (feel free to fork and fix/extend).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Erlang Spacewar]]></title>
    <link href="http://noisycode.com/blog/2013/03/02/testing-erlang-spacewar/"/>
    <updated>2013-03-02T15:31:00-08:00</updated>
    <id>http://noisycode.com/blog/2013/03/02/testing-erlang-spacewar</id>
    <content type="html"><![CDATA[<h2>What&rsquo;s Erlang Spacewar?</h2>

<p>A multiplayer version of <a href="http://en.wikipedia.org/wiki/Spacewar!">Spacewar!</a> built in <a href="http://erlang.org">Erlang</a> with <a href="https://github.com/extend/cowboy">Cowboy</a> using websockets.  For the moment, it&rsquo;s quite basic and really intended to be a proof-of-concept.  The idea was to see if it is even <em>possible</em> to use websockets for this sort of thing.</p>

<p>Right now I&rsquo;m just trying to get a sense of how it performs on a tiny little EC2 VM so I&rsquo;d be most grateful if you could grab a couple friends and jump in when you have a few minutes to spare.  Fair warning:  I fully expect it to fall over and die if there are more than 50 or so people in there but I guess we&rsquo;ll find out.</p>

<p>I&rsquo;ll give you the link to play, don&rsquo;t worry, just a couple quick things&hellip;</p>

<h2>How Long Will It Work For?</h2>

<p>I&rsquo;m going to keep it live (aside from crashes, etc) for at least a couple of weeks I think.</p>

<h2>What You Need:</h2>

<p>A browser that supports websockets and HTML canvas.  Think recent versions of Chrome and Firefox, Safari <em>should</em> work.</p>

<h2>Problems You Can Expect</h2>

<h3>It&rsquo;s Ugly</h3>

<p>And I know.  No explosions yet, very minimal.</p>

<h3>It&rsquo;s Choppy Sometimes</h3>

<p>It&rsquo;s running on a t1.micro in Amazon EC2&rsquo;s us-east-1 region.</p>

<p><strong>Translation</strong>:  it&rsquo;s got less than a full CPU core (really just uses spare cycles from other bigger VMs) and it&rsquo;s in Virginia so if you&rsquo;re on the West coast like me, expect some lag.</p>

<h3>Crashes/Termination</h3>

<p>I&rsquo;ll be messing with the code for the next week so do expect unavailability due to upgrades and crashes.</p>

<h2>Please Do</h2>

<h3>Play it and tell me what you think</h3>

<p>I know about choppiness and ugliness but if you find any other frustrating bits (or even stuff you love), please do tell me in the comments or on <a href="http://twitter.com/j14159">Twitter</a>.</p>

<h3>Share the link</h3>

<p>But please share the link to this blog post &ndash; I&rsquo;d like to give all test players the same warnings/notes I&rsquo;m giving you.</p>

<h2>Are You Going To Release The Source?</h2>

<p>Yes.  It&rsquo;ll be reasonably open (probably BSD or MIT license) on my <a href="https://github.com/j14159">github account</a> within a couple of weeks.  I&rsquo;m still cleaning things up and moving to gen_server/proper OTP instead of bare Erlang processes.</p>

<p>For the record, the repository will contain the grim history of almost all my mistakes.  It&rsquo;s been a learning experience.</p>

<h1>Shut Up And Let Me Play!</h1>

<p>Of course.  Here&rsquo;s the game, don&rsquo;t forget to enter a username and click &ldquo;Start Playing&rdquo;:  <a href="http://esw.noisycode.com:8080/sw.html">Erlang Websocket Spacewar!</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parser N00b]]></title>
    <link href="http://noisycode.com/blog/2013/02/02/parser-n00b/"/>
    <updated>2013-02-02T14:27:00-08:00</updated>
    <id>http://noisycode.com/blog/2013/02/02/parser-n00b</id>
    <content type="html"><![CDATA[<h1>Or: WTF, A LISP in Scala?</h1>

<p><a href="https://github.com/j14159/BadLisp">Project link for the lazy</a></p>

<h2>How Did It Come To This?</h2>

<p>Some background first.  At my <a href="http://hootsuite.com">day job</a>, we&rsquo;ve ended up writing a lot of boilerplate for REST endpoints with Netty (it&rsquo;s relevant, I&rsquo;ll get to the LISP bit soon).  While I don&rsquo;t want to get into it too much as we&rsquo;ll likely be open-sourcing the results, we didn&rsquo;t go with bigger solutions (e.g. Jetty, Scalatra, Play) because when you do, you&rsquo;re making one or more of the following trade-offs (at minimum) in favour of an easier API for writing HTTP stuff:</p>

<ul>
<li>lack of visibility into how concurrency is handled at all levels of your application</li>
<li>much bigger artifacts to deploy (unless you&rsquo;re a ProGuard ninja)</li>
<li>dealing with someone else&rsquo;s assumptions about how HTTP-involved code (not necessarily a full &ldquo;web app&rdquo;) should be written</li>
</ul>


<p>That third point is fuel for a much longer post/many discussions well outside the scope of this one.  I&rsquo;m happy to drink beer and yell about it with you if you&rsquo;re ever in Vancouver.</p>

<p>To be clear:  the above points <strong>DO NOT MATTER</strong> if you&rsquo;re writing something that&rsquo;s going on decent hardware (big servers) and/or you&rsquo;re only dealing with a few hundred concurrent connections with DB/cache/distributed communication involved (echo and static file servers are a completely different story).  Even that still depends greatly on the nature of your app and where you&rsquo;re running it.  The first point can also be mitigated by diving into the source for whatever library/framework you select but that will only get you so far, especially if you&rsquo;ve got a larger team.  We went the direction that we did because we need to deal with thousands of concurrent inbound connections per server with lots of DB and cache interactions on M1 medium through M1 large EC2 VMs. In this situation transparency and simple configurability at each layer of the application are necessities.</p>

<p>Just in case:  there are other reasons we didn&rsquo;t go with Finatra but I&rsquo;ve already gone on too long.</p>

<h3>Getting To The LISP Bit</h3>

<p>The upshot of everything I said above is that we needed a basic routing DSL/library on top of Netty.  Since we need to provide both static and dynamic paths, it seemed natural to start looking at combinatorial parsers (if you&rsquo;re curious, go read <a href="http://www.codecommit.com/blog/scala/the-magic-behind-parser-combinators">this post</a> by <a href="https://twitter.com/djspiewak">Daniel Spiewak</a>).  After some initial fumbling with regex and possible path parsers, I decided to see what I could do with S-expressions.  This was the initial result:</p>

<div><script src='https://gist.github.com/4424770.js'></script>
<noscript><pre><code></code></pre></noscript></div>


<p>Once I had progressed a bit further, it seemed natural to see how easily I could add simple evaluation of basic math operators (+, &ndash;, / and *).</p>

<p>Short answer:  <em>easy</em></p>

<p>Result:  I got sucked in and went overboard, <a href="https://github.com/j14159/BadLisp">clearly</a>.</p>

<h2>A Slight Tangent</h2>

<p>Before I get into what was good and bad about my first LISP implementation experience, it bears briefly demonstrating the way these experiments have resulted in a solution for the original problem:  we need a simple, transparent, configurable routing layer on top of Netty.  Our library &ldquo;Floor&rdquo; was built with a single goal in mind &ndash; ruthless minimalism while staying <a href="http://en.wikipedia.org/wiki/Don't_repeat_yourself">DRY</a>.</p>

<p>Here&rsquo;s a very simple example of what Floor lets you do:</p>

<div><script src='https://gist.github.com/4699916.js'></script>
<noscript><pre><code></code></pre></noscript></div>


<p>There&rsquo;s a bit more to it than that but I&rsquo;m sure you get the idea.</p>

<h2>The Good Stuff</h2>

<p>I got to dig a bit further into a couple areas that I haven&rsquo;t before and they&rsquo;re worth mentioning.  If/when Floor goes open source, you&rsquo;ll see a lot of the same stuff in it.</p>

<h3>Partial Functions and Pattern Matching</h3>

<p>Looking at the various traits that are bolted onto the <a href="https://github.com/j14159/BadLisp">BadLisp</a> interpreter, you&rsquo;ll see that pretty much everything is done via filtering lists of partial functions based on pattern matching.  Both special forms (like &ldquo;if-then-else&rdquo;) and the simple built-in functions (e.g. +, &ndash;, car) are implemented this way.  Check out <a href="https://github.com/j14159/BadLisp/blob/master/src/main/scala/com/noisycode/Conditionals.scala">Conditionals.scala</a> for a brief example.  I generally like this approach and for the most part find it clean but it <em>does</em> have some downsides which I&rsquo;ll touch on shortly.</p>

<h3>Implicit Classes</h3>

<p>New in Scala 2.10, I&rsquo;m sure they&rsquo;ll be as contentious as implicit defs and vals were before.  Regardless, I stuck one in for the <a href="https://github.com/j14159/BadLisp/blob/master/src/main/scala/com/noisycode/Comparisons.scala">Comparisons</a> trait.  I treat it a little bit like a type class in that it allows certain value-based methods to be used with classes <a href="https://github.com/j14159/BadLisp">BadLisp</a> considers to be concrete values.  I suspect based on some of the reading I&rsquo;ve done that this is not precisely what is meant by type classes in Scala but I think it&rsquo;s a step in the right direction for the moment.</p>

<h2>The Bad Stuff</h2>

<h3>Not Enough Implicit Classes</h3>

<p>Again, probably a contentious point.  I do get the feeling, however, that I could have simplified even more with judicious use of these.  It&rsquo;s not something I&rsquo;m going to go back and refactor for but something I&rsquo;m going to keep top of mind for future stuff.  Please do weigh in via comments or <a href="http://twitter.com/j14159">Twitter</a> if you have strong feelings one way or the other about this though.</p>

<h3>Partial Functions and the Symbol Table</h3>

<p>Because my symbol table is simply a big list of partial functions that I match against, it&rsquo;s a bit clunky to look up or alias things in the case of higher order functions (I just wrapped this one up this morning).  I&rsquo;m not especially proud of how functions and scope <a href="https://github.com/j14159/BadLisp/blob/master/src/main/scala/com/noisycode/Definitions.scala">are handled</a> at present but I think I&rsquo;m going to leave well enough alone as I seriously doubt this is the last time I try to implement something like this.</p>

<h2>Next</h2>

<p>I won&rsquo;t be working on this particular interpreter further but am happy to talk about anything you find deficient and/or interesting on <a href="http://twitter.com/j14159">Twitter</a> or in the comments.  Next steps for me are getting back to <a href="https://github.com/j14159/PawnShop">PawnShop</a> and/or experimenting with some Actor and Disruptor implementations I think.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Posterity 00: IA32 Memory Management]]></title>
    <link href="http://noisycode.com/blog/2012/10/23/posterity-00-ia32-memory-management/"/>
    <updated>2012-10-23T19:37:00-07:00</updated>
    <id>http://noisycode.com/blog/2012/10/23/posterity-00-ia32-memory-management</id>
    <content type="html"><![CDATA[<p>Roughly 10 years ago, <a href="http://www.semisafe.com/">Cameron</a> and I were roommates.  At the time, he was getting into computer security, talking about NOP sleds and shell code while I ranted about how the Intel memory model <em>could</em> prevent it if people used it correctly.  Thankfully he talked me out of writing something antagonistic and a brief <a href="https://dl.dropbox.com/u/84389790/memory.pdf">introduction to Intel memory management</a> resulted.</p>

<p>There are some notable weaknesses including:</p>

<ul>
<li>no mention of how caching figures in</li>
<li>little to no talk of actually securing things</li>
<li>it&rsquo;s IA32, so kind of out of date (bear in mind this was 10 years ago)</li>
</ul>


<p>I intended some sort of followup that covered safer process address space construction using non-executable heaps but unfortunately never got around to it.  Nevertheless, I figured it might be of interest to some people so <a href="https://dl.dropbox.com/u/84389790/memory.pdf">share and enjoy</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learning Erlang + Clojure for Some Good]]></title>
    <link href="http://noisycode.com/blog/2012/10/21/pawnshop-in-which-i-learn-erlang-and-clojure-for-some-good/"/>
    <updated>2012-10-21T17:22:00-07:00</updated>
    <id>http://noisycode.com/blog/2012/10/21/pawnshop-in-which-i-learn-erlang-and-clojure-for-some-good</id>
    <content type="html"><![CDATA[<h2>Background</h2>

<p>Since pretty much everything I do at my <a href="http://twitter.com/hootsuite">day job</a> involves Akka and Scala, Erlang&rsquo;s been on my radar for quite a while.  Using RabbitMQ in current products and considering Riak to solve some nasty storage issues has of course heightened my interest in it as well.  Thanks to <a href="http://twitter.com/ujm">@ujm</a> and <a href="http://twitter.com/tavisrudd">@tavisrudd</a> I&rsquo;ve also been hearing a lot about Clojure for the past year or so and it has (not so) mysteriously turned up in a few testing tools at the aforementioned day job due to <a href="http://twitter.com/ujm">@ujm</a>&rsquo;s unbridled love for it.  As I&rsquo;ve been trying to improve my own approach to and understanding of functional programming, it seemed both natural and frankly exciting to dive into something involving both.</p>

<h2>The Pitfall</h2>

<p>This brings up a minor pet peeve of mine:  while evaluating something new and interesting, people often come up with trivial example projects and in the past, I&rsquo;ve been possibly more guilty than most.  This is something I want very much to avoid now.  The problems I&rsquo;ve seen in myself with using something <em>too</em> trivial to evaluate and learn new things are:</p>

<ul>
<li>performance assumptions are never grounded in reality when your code doesn&rsquo;t do anything realistic.  A perfect example is testing concurrent websocket connection limits that simply echo input (I did this with Play! 2.0 and I&rsquo;ve seen some naive numbers from the node.js crowd mentioned lately as well).</li>
<li>simple projects rarely expose some of the strange corners of a language or platform.  Anyone who has extensively used Scala&rsquo;s implicits or made extensive use of futures and promises will understand this.</li>
<li>most importantly overly trivial projects won&rsquo;t expose your <strong>own</strong> weaknesses and misunderstandings early on.</li>
</ul>


<h2>Some Goals</h2>

<p>Given the above, there are a few specific challenges I&rsquo;m looking to work on with this project in both Erlang and Clojure:</p>

<ul>
<li>unique ID generation without a central locking resource.  I want to be able to establish total ordering without any central coordination.  <em>Loose</em> temporal ordering is a nice to have.</li>
<li>horizontal scale, add and remove additional resources with no coordination required beyond some configuration.  As long as nodes can get in touch with the database, they should continue to function.</li>
</ul>


<p>And I have a few goals specific to Clojure and Erlang:</p>

<ul>
<li>learn to use their build tools (Leiningen and Rebar)</li>
<li>loosen my reliance on object orientation</li>
<li>get more comfortable with dynamic typing (I tend to yell a lot about the supremacy of static typing).</li>
<li>experiment with a heterogeneous solution.  I&rsquo;ll be building the same thing in both languages so I think some interesting comparisons could arise with regard to things like deployment, configuration and performance.</li>
</ul>


<p>Naturally I&rsquo;m going to make a few rules for myself, the first and most important being that I&rsquo;m not going to hide my mistakes.  When I change my mind or screw up, all the details will be in the commit history.  Second, the whole thing will be open source so that anyone will be able to see my pace, changes and progress in github at any time.
Lastly, I&rsquo;ll welcome feedback and optimization suggestions(with credit given where credit is due) but won&rsquo;t accept pull requests or massive rewrites from anyone &ndash; this is mine to learn and mess up.</p>

<h2>The Actual Project</h2>

<p>I&rsquo;m going to build a simple URL shortener and image hosting service called <a href="http://github.com/j14159/PawnShop">PawnShop</a> with the following basic features:</p>

<ul>
<li>exchange a URL for a short hash</li>
<li>redirect short URLs to originals</li>
<li>upload an image (png/jpeg) in return for a short hash</li>
<li>redirect HTTP requests for a URL hash to the original</li>
<li>display the matching submitted image for a given requested hash</li>
<li>track click stats for each hash generated.  I&rsquo;ll store these at millisecond resolution.</li>
<li>display hosted images inside a minimal template</li>
<li>provide a REST API to retrieve click stats, likely report by one hour intervals at the smallest at first.</li>
<li>basic authentication via email address and password</li>
</ul>


<p>The nice-to-have features will be:</p>

<ul>
<li>click stat reports/graphs with D3.js</li>
<li>pluggable authentication</li>
</ul>


<p>The basic technical bits:</p>

<ul>
<li>This will be a single monolithic project, no interdependent services.</li>
<li>It will be heterogeneous in that I want to be able to run the Erlang version side by side with the Clojure version in the same cluster, off the same database, behind the same load balancer and things should Just Work &trade;.</li>
<li>I&rsquo;m going to use standard web frameworks, likely <a href="http://webnoir.org">Noir</a> and either <a href="http://chicagoboss.org">Chicago Boss</a> or <a href="http://nitrogenproject.com">Nitrogen</a></li>
<li>The only data store I&rsquo;ll be using is Riak.</li>
</ul>


<h2>Following Along</h2>

<p>I&rsquo;m going to aim for roughly a post-per-week here.  Blog posts related to PawnShop will essentially be a notebook/journal of my reasoning for certain decisions as well as both negative and positive experiences throughout the learning and development process.</p>

<p><a href="http://github.com/j14159/PawnShop"><strong>GitHub</strong></a></p>

<p><a href="https://trello.com/board/pawnshop/5084584abfe3e0931a00fdce"><strong>Trello</strong></a></p>

<h2>Riak and the Data Model</h2>

<p>A while ago, <a href="http://twitter.com/jamesgolick">@jamesgolick</a> told me I wasn&rsquo;t allowed to use Riak until I had read the famous Dynamo paper in its entirety.  He&rsquo;s right, and you should <a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf">read it too</a> if you haven&rsquo;t yet.</p>

<p>A URL shortener model seems a great fit for an eventually consistent Dynamo-style store like Riak.</p>

<ul>
<li>To shorten URLs and host pictures, you want high consistency for DB writes meaning that when a user submits new data, you want the write to complete with reasonable certainty.</li>
<li>To retrieve URLs, low read consistency (small quorum) is OK.  Since we&rsquo;re not <strong>mutating</strong> URL and picture entries, we don&rsquo;t have to worry about an update that might not have hit replicas yet.</li>
<li>To add and retrieve click stats, low read and write consistency is fine.  Missing one or two clicks out of thousands for a single report isn&rsquo;t the end of the world, we just want reasonable accuracy when the stats are requested and eventually high accuracy.  If it takes a few hours for this to happen, so be it.</li>
</ul>


<h2>Assumptions/Dependencies</h2>

<h3>statsd</h3>

<p>Since I&rsquo;m going to monitor the hell out of everything, I&rsquo;ll assume something statsd-compatible is available wherever this project runs.  These days I don&rsquo;t think this is really an option at all for any sort of sane environment.</p>

<h2>Next Steps</h2>

<p>The next few posts will likely cover the following topics:</p>

<ul>
<li>decentralized ID/hash generation</li>
<li>Riak model for shortened links and picture data</li>
<li>Riak model for click stats</li>
</ul>


<p>But those could change at any time.</p>

<p>Comments/questions always welcome on <a href="http://twitter.com/j14159">Twitter</a></p>
]]></content>
  </entry>
  
</feed>
